{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2hoGGRkQCd5y"
      ],
      "authorship_tag": "ABX9TyM77C2eaHeaPXBHHmYgMvx1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Celest14l/Automated-Mail/blob/main/Automated_Mail.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DO not TOuch this code"
      ],
      "metadata": {
        "id": "nqy30zu2CYGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrjHKpa6_IeX",
        "outputId": "355f096d-7f93-4ef8-c6b4-1c1f9609e8b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enJ6W40vUvWS",
        "outputId": "d24787f6-8bc3-4ce2-fd40-05acf9b5adb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUFwWsli_d83",
        "outputId": "098af4af-26df-469e-857f-8309373c7981"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.4 (from gradio)\n",
            "  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.12.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.4-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.12.0 gradio-client-1.5.4 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "fHmz8dF3-7jF",
        "outputId": "758598fb-42d3-4830-f2ea-68d542d3cceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ddeeeff79cd2b10361.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ddeeeff79cd2b10361.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import smtplib\n",
        "from email.message import EmailMessage\n",
        "from dotenv import load_dotenv\n",
        "import gradio as gr\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(dotenv_path=\".env\")  # Ensure `.env` file exists in the same directory\n",
        "\n",
        "# Credentials\n",
        "smtp_host = \"smtp.gmail.com\"\n",
        "email_user = os.getenv(\"EMAIL_USER\")\n",
        "email_pass = os.getenv(\"EMAIL_PASS\")\n",
        "\n",
        "# Validate email credentials\n",
        "if not email_user or not email_pass:\n",
        "    raise ValueError(\"Missing EMAIL_USER or EMAIL_PASS in .env file.\")\n",
        "\n",
        "# Load GPT-Neo model and tokenizer\n",
        "model_name = \"EleutherAI/gpt-neo-1.3B\"  # Model name\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPTNeoForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Function to generate text using GPT-Neo\n",
        "def generate_text_gpt_neo(prompt):\n",
        "    try:\n",
        "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "        outputs = model.generate(inputs, max_length=150, temperature=0.7, num_return_sequences=1)\n",
        "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return generated_text\n",
        "    except Exception as e:\n",
        "        return f\"Error in text generation: {str(e)}\"\n",
        "\n",
        "# Function to send an email\n",
        "def send_email(to_email, subject, content):\n",
        "    try:\n",
        "        if not to_email or not subject or not content:\n",
        "            return \"Error: Missing required fields.\"\n",
        "\n",
        "        with smtplib.SMTP_SSL(smtp_host, 465) as server:\n",
        "            server.login(email_user, email_pass)\n",
        "            msg = EmailMessage()\n",
        "            msg[\"From\"] = email_user\n",
        "            msg[\"To\"] = to_email\n",
        "            msg[\"Subject\"] = subject\n",
        "            msg.set_content(content)\n",
        "            server.send_message(msg)\n",
        "            return f\"Email sent successfully to {to_email} with subject: {subject}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error sending email: {str(e)}\")\n",
        "        return f\"Error sending email: {str(e)}\"\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_interface():\n",
        "    def compose_and_send_email(subject_prompt, recipient):\n",
        "        if not subject_prompt or not recipient:\n",
        "            return \"Error: Subject prompt and recipient email are required.\", \"\"\n",
        "\n",
        "        # Generate email content based on the prompt\n",
        "        content = generate_text_gpt_neo(f\"Compose a professional email with the subject: {subject_prompt}\")\n",
        "        subject = f\"Generated Email: {subject_prompt[:50]}\"  # Truncate subject for clarity\n",
        "\n",
        "        # Send the email\n",
        "        send_status = send_email(recipient, subject, content)\n",
        "        return send_status, content\n",
        "\n",
        "    with gr.Blocks() as interface:\n",
        "        gr.Markdown(\"# AI-Powered Email Composer\")\n",
        "        subject_prompt = gr.Textbox(label=\"Prompt for Email Content\", placeholder=\"Describe the email topic...\")\n",
        "        recipient_email = gr.Textbox(label=\"Recipient Email\", placeholder=\"Enter recipient email\")\n",
        "        # Use interactive=False instead of readonly\n",
        "        send_status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "        generated_email = gr.Textbox(label=\"Generated Email Content\", interactive=False)\n",
        "        send_btn = gr.Button(\"Generate and Send Email\")\n",
        "\n",
        "        send_btn.click(\n",
        "            fn=compose_and_send_email,\n",
        "            inputs=[subject_prompt, recipient_email],\n",
        "            outputs=[send_status, generated_email]\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interface = gradio_interface()\n",
        "    interface.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API calls"
      ],
      "metadata": {
        "id": "TMjUicPwvEAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "HF_API_URL = \"https://api-inference.huggingface.co/models/bigscience/bloom-560m\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {huggingface_api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "payload = {\n",
        "    \"inputs\": \"Test input to check API key access.\",\n",
        "    \"parameters\": {\"max_new_tokens\": 150, \"temperature\": 0.7}\n",
        "}\n",
        "\n",
        "response = requests.post(HF_API_URL, headers=headers, json=payload)\n",
        "print(\"Status Code:\", response.status_code)\n",
        "print(\"Response:\", response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXN1BN_3ePW2",
        "outputId": "500acf08-3f57-4fb5-c0ac-96d83c80103a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 503\n",
            "Response: {\"error\":\"Model bigscience/bloom-560m is currently loading\",\"estimated_time\":44.73716735839844}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use this Main functions"
      ],
      "metadata": {
        "id": "2hoGGRkQCd5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "// Sending Mails via Bot"
      ],
      "metadata": {
        "id": "IAfP7HUVtN6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import smtplib\n",
        "from email.message import EmailMessage\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(dotenv_path=\"pass.env\")\n",
        "\n",
        "# Email credentials\n",
        "email_user = os.getenv(\"EMAIL_USER\")\n",
        "email_pass = os.getenv(\"EMAIL_PASS\")\n",
        "smtp_host = \"smtp.gmail.com\"\n",
        "\n",
        "def send_email_with_attachments(to_email, subject, body_content, attachments=[]):\n",
        "    \"\"\"\n",
        "    Function to send an email with the given subject, body content, and optional attachments.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create an email message\n",
        "        msg = EmailMessage()\n",
        "        msg[\"From\"] = email_user\n",
        "        msg[\"To\"] = to_email\n",
        "        msg[\"Subject\"] = subject\n",
        "        msg.set_content(body_content)\n",
        "\n",
        "        # Add attachments if any\n",
        "        for file_path in attachments:\n",
        "            with open(file_path.name, \"rb\") as file:\n",
        "                file_data = file.read()\n",
        "                file_name = os.path.basename(file_path.name)\n",
        "                msg.add_attachment(file_data, maintype=\"application\", subtype=\"octet-stream\", filename=file_name)\n",
        "\n",
        "        # Send the email\n",
        "        with smtplib.SMTP_SSL(smtp_host, 465) as server:\n",
        "            server.login(email_user, email_pass)\n",
        "            server.send_message(msg)\n",
        "            return f\"Email sent successfully to {to_email}.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error sending email: {str(e)}\"\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_email_interface(to_email, subject, body_content, attachments):\n",
        "    return send_email_with_attachments(to_email, subject, body_content, attachments)\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=gradio_email_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Recipient Email\", placeholder=\"Enter recipient's email\"),\n",
        "        gr.Textbox(label=\"Subject\", placeholder=\"Enter email subject\"),\n",
        "        gr.Textbox(label=\"Message Content\", placeholder=\"Type your email content here...\"),\n",
        "        gr.Files(label=\"Attachments (optional)\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Email Sender\",\n",
        "    description=\"Send emails with optional attachments using Gradio.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "XrbL__Z3BCN8",
        "outputId": "cdccb692-652a-4c48-9a29-edd0c8fb26a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://54cf022b93d69d6d92.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://54cf022b93d69d6d92.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYt9CUrfsU5R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}